{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kang-Schafer Simulation\n",
    "\n",
    "This notebook demonstrates the use of permutation weighting on the classic Kang-Schafer simulation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-25T14:29:06.058554Z",
     "start_time": "2025-02-25T14:29:06.050926Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'PW' from 'permutation_weighting' (/Users/johannesmuller/Documents/github/permutation_weighting/permutation_weighting/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mseaborn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01msns\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpermutation_weighting\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PW\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mstatsmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01msm\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Set plotting style\u001B[39;00m\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'PW' from 'permutation_weighting' (/Users/johannesmuller/Documents/github/permutation_weighting/permutation_weighting/__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from permutation_weighting import PW\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Kang-Schafer Data\n",
    "\n",
    "We'll recreate the simulation setup from Kang and Schafer (2007)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_kang_schafer_data(n=1000, misspecified=False):\n",
    "    # Generate covariates\n",
    "    X = np.random.normal(size=(n, 4))\n",
    "    \n",
    "    # Generate propensity scores\n",
    "    propensity = 1 / (1 + np.exp(X[:, 0] - 0.5 * X[:, 1] + 0.25 * X[:, 2] + 0.1 * X[:, 3]))\n",
    "    \n",
    "    # Generate treatment\n",
    "    A = np.random.binomial(1, propensity, size=n)\n",
    "    \n",
    "    # Generate outcome (true effect is 0)\n",
    "    Y = 210 + 27.4 * X[:, 0] + 13.7 * X[:, 1] + 13.7 * X[:, 2] + 13.7 * X[:, 3] + np.random.normal(size=n)\n",
    "    \n",
    "    # Store true data\n",
    "    true_X = X.copy()\n",
    "    \n",
    "    # Apply transformation if misspecified\n",
    "    if misspecified:\n",
    "        X = np.column_stack([\n",
    "            np.exp(X[:, 0] / 2),\n",
    "            X[:, 1] * (1 + np.exp(X[:, 0])) ** (-1) + 10,\n",
    "            (X[:, 0] * X[:, 2] / 25 + 0.6) ** 3,\n",
    "            (X[:, 1] + X[:, 3] + 20) ** 2\n",
    "        ])\n",
    "    \n",
    "    return A, X, Y, true_X, propensity\n",
    "\n",
    "# Generate data\n",
    "A, X, Y, true_X, propensity = generate_kang_schafer_data(n=1000, misspecified=False)\n",
    "A_mis, X_mis, Y_mis, true_X_mis, propensity_mis = generate_kang_schafer_data(n=1000, misspecified=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate Weights with Permutation Weighting\n",
    "\n",
    "Let's estimate weights using different classifiers and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate weights with logistic regression\n",
    "pw_logit = PW(A, X, classifier='logit', num_replicates=100)\n",
    "pw_logit_mis = PW(A_mis, X_mis, classifier='logit', num_replicates=100)\n",
    "\n",
    "# Estimate weights with boosting\n",
    "pw_boost = PW(A, X, classifier='boosting', num_replicates=100)\n",
    "pw_boost_mis = PW(A_mis, X_mis, classifier='boosting', num_replicates=100)\n",
    "\n",
    "# Estimate weights with SGD logistic regression\n",
    "pw_sgd = PW(A, X, classifier='logit', num_replicates=100, use_sgd=True)\n",
    "pw_sgd_mis = PW(A_mis, X_mis, classifier='logit', num_replicates=100, use_sgd=True)\n",
    "\n",
    "# Estimate weights with neural network\n",
    "pw_nn = PW(A, X, classifier='neural_net', num_replicates=100, use_sgd=True)\n",
    "pw_nn_mis = PW(A_mis, X_mis, classifier='neural_net', num_replicates=100, use_sgd=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate Average Treatment Effects\n",
    "\n",
    "Now, let's estimate the average treatment effect (ATE) using the different weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_ate(Y, A, weights=None):\n",
    "    if weights is None:\n",
    "        result = sm.OLS(Y, sm.add_constant(A)).fit()\n",
    "    else:\n",
    "        result = sm.WLS(Y, sm.add_constant(A), weights=weights).fit()\n",
    "    \n",
    "    return result.params[1], result.bse[1]\n",
    "\n",
    "# Estimate ATE with various methods\n",
    "results = []\n",
    "\n",
    "# Correctly specified model\n",
    "results.append({\n",
    "    'Method': 'Unweighted',\n",
    "    'Misspecified': False,\n",
    "    'ATE': estimate_ate(Y, A)[0],\n",
    "    'SE': estimate_ate(Y, A)[1]\n",
    "})\n",
    "\n",
    "results.append({\n",
    "    'Method': 'PW (Logistic)',\n",
    "    'Misspecified': False,\n",
    "    'ATE': estimate_ate(Y, A, pw_logit['weights'])[0],\n",
    "    'SE': estimate_ate(Y, A, pw_logit['weights'])[1]\n",
    "})\n",
    "\n",
    "results.append({\n",
    "    'Method': 'PW (Boosting)',\n",
    "    'Misspecified': False,\n",
    "    'ATE': estimate_ate(Y, A, pw_boost['weights'])[0],\n",
    "    'SE': estimate_ate(Y, A, pw_boost['weights'])[1]\n",
    "})\n",
    "\n",
    "results.append({\n",
    "    'Method': 'PW (SGD)',\n",
    "    'Misspecified': False,\n",
    "    'ATE': estimate_ate(Y, A, pw_sgd['weights'])[0],\n",
    "    'SE': estimate_ate(Y, A, pw_sgd['weights'])[1]\n",
    "})\n",
    "\n",
    "results.append({\n",
    "    'Method': 'PW (Neural Net)',\n",
    "    'Misspecified': False,\n",
    "    'ATE': estimate_ate(Y, A, pw_nn['weights'])[0],\n",
    "    'SE': estimate_ate(Y, A, pw_nn['weights'])[1]\n",
    "})\n",
    "\n",
    "# Misspecified model\n",
    "results.append({\n",
    "    'Method': 'Unweighted',\n",
    "    'Misspecified': True,\n",
    "    'ATE': estimate_ate(Y_mis, A_mis)[0],\n",
    "    'SE': estimate_ate(Y_mis, A_mis)[1]\n",
    "})\n",
    "\n",
    "results.append({\n",
    "    'Method': 'PW (Logistic)',\n",
    "    'Misspecified': True,\n",
    "    'ATE': estimate_ate(Y_mis, A_mis, pw_logit_mis['weights'])[0],\n",
    "    'SE': estimate_ate(Y_mis, A_mis, pw_logit_mis['weights'])[1]\n",
    "})\n",
    "\n",
    "results.append({\n",
    "    'Method': 'PW (Boosting)',\n",
    "    'Misspecified': True,\n",
    "    'ATE': estimate_ate(Y_mis, A_mis, pw_boost_mis['weights'])[0],\n",
    "    'SE': estimate_ate(Y_mis, A_mis, pw_boost_mis['weights'])[1]\n",
    "})\n",
    "\n",
    "results.append({\n",
    "    'Method': 'PW (SGD)',\n",
    "    'Misspecified': True,\n",
    "    'ATE': estimate_ate(Y_mis, A_mis, pw_sgd_mis['weights'])[0],\n",
    "    'SE': estimate_ate(Y_mis, A_mis, pw_sgd_mis['weights'])[1]\n",
    "})\n",
    "\n",
    "results.append({\n",
    "    'Method': 'PW (Neural Net)',\n",
    "    'Misspecified': True,\n",
    "    'ATE': estimate_ate(Y_mis, A_mis, pw_nn_mis['weights'])[0],\n",
    "    'SE': estimate_ate(Y_mis, A_mis, pw_nn_mis['weights'])[1]\n",
    "})\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df['True ATE'] = 0.0  # True ATE is 0\n",
    "results_df['Bias'] = results_df['ATE'] - results_df['True ATE']\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results\n",
    "\n",
    "Let's visualize the estimation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ATEs\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot correctly specified model results\n",
    "plt.subplot(1, 2, 1)\n",
    "correct_df = results_df[results_df['Misspecified'] == False]\n",
    "plt.errorbar(\n",
    "    correct_df['Method'], \n",
    "    correct_df['ATE'], \n",
    "    yerr=correct_df['SE'], \n",
    "    fmt='o', \n",
    "    capsize=5, \n",
    "    color='blue'\n",
    ")\n",
    "plt.axhline(y=0, color='r', linestyle='--', label='True ATE')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Correctly Specified Model')\n",
    "plt.ylabel('ATE Estimate')\n",
    "plt.ylim(-3, 3)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot misspecified model results\n",
    "plt.subplot(1, 2, 2)\n",
    "mis_df = results_df[results_df['Misspecified'] == True]\n",
    "plt.errorbar(\n",
    "    mis_df['Method'], \n",
    "    mis_df['ATE'], \n",
    "    yerr=mis_df['SE'], \n",
    "    fmt='o', \n",
    "    capsize=5, \n",
    "    color='orange'\n",
    ")\n",
    "plt.axhline(y=0, color='r', linestyle='--', label='True ATE')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Misspecified Model')\n",
    "plt.ylabel('ATE Estimate')\n",
    "plt.ylim(-10, 10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Weight Distributions\n",
    "\n",
    "Let's look at the distributions of weights from different methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot weight distributions for correctly specified model\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.histplot(pw_logit['weights'], bins=50, alpha=0.5, label='Logistic')\n",
    "plt.xlim(0, 5)\n",
    "plt.title('Correctly Specified: Logistic')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.histplot(pw_boost['weights'], bins=50, alpha=0.5, label='Boosting')\n",
    "plt.xlim(0, 5)\n",
    "plt.title('Correctly Specified: Boosting')\n",
    "\n",
    "# Plot weight distributions for misspecified model\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.histplot(pw_logit_mis['weights'], bins=50, alpha=0.5, label='Logistic')\n",
    "plt.xlim(0, 5)\n",
    "plt.title('Misspecified: Logistic')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.histplot(pw_boost_mis['weights'], bins=50, alpha=0.5, label='Boosting')\n",
    "plt.xlim(0, 5)\n",
    "plt.title('Misspecified: Boosting')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Balance Metrics\n",
    "\n",
    "Let's look at the balance metrics (MSE and LogLoss) for different methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract balance metrics\n",
    "balance_metrics = []\n",
    "\n",
    "# Correctly specified model\n",
    "balance_metrics.append({\n",
    "    'Method': 'PW (Logistic)',\n",
    "    'Misspecified': False,\n",
    "    'MSE': pw_logit['train']['MSEEvaluator'],\n",
    "    'LogLoss': pw_logit['train']['LogLossEvaluator']\n",
    "})\n",
    "\n",
    "balance_metrics.append({\n",
    "    'Method': 'PW (Boosting)',\n",
    "    'Misspecified': False,\n",
    "    'MSE': pw_boost['train']['MSEEvaluator'],\n",
    "    'LogLoss': pw_boost['train']['LogLossEvaluator']\n",
    "})\n",
    "\n",
    "balance_metrics.append({\n",
    "    'Method': 'PW (SGD)',\n",
    "    'Misspecified': False,\n",
    "    'MSE': pw_sgd['train']['MSEEvaluator'],\n",
    "    'LogLoss': pw_sgd['train']['LogLossEvaluator']\n",
    "})\n",
    "\n",
    "balance_metrics.append({\n",
    "    'Method': 'PW (Neural Net)',\n",
    "    'Misspecified': False,\n",
    "    'MSE': pw_nn['train']['MSEEvaluator'],\n",
    "    'LogLoss': pw_nn['train']['LogLossEvaluator']\n",
    "})\n",
    "\n",
    "# Misspecified model\n",
    "balance_metrics.append({\n",
    "    'Method': 'PW (Logistic)',\n",
    "    'Misspecified': True,\n",
    "    'MSE': pw_logit_mis['train']['MSEEvaluator'],\n",
    "    'LogLoss': pw_logit_mis['train']['LogLossEvaluator']\n",
    "})\n",
    "\n",
    "balance_metrics.append({\n",
    "    'Method': 'PW (Boosting)',\n",
    "    'Misspecified': True,\n",
    "    'MSE': pw_boost_mis['train']['MSEEvaluator'],\n",
    "    'LogLoss': pw_boost_mis['train']['LogLossEvaluator']\n",
    "})\n",
    "\n",
    "balance_metrics.append({\n",
    "    'Method': 'PW (SGD)',\n",
    "    'Misspecified': True,\n",
    "    'MSE': pw_sgd_mis['train']['MSEEvaluator'],\n",
    "    'LogLoss': pw_sgd_mis['train']['LogLossEvaluator']\n",
    "})\n",
    "\n",
    "balance_metrics.append({\n",
    "    'Method': 'PW (Neural Net)',\n",
    "    'Misspecified': True,\n",
    "    'MSE': pw_nn_mis['train']['MSEEvaluator'],\n",
    "    'LogLoss': pw_nn_mis['train']['LogLossEvaluator']\n",
    "})\n",
    "\n",
    "# Convert to DataFrame\n",
    "balance_df = pd.DataFrame(balance_metrics)\n",
    "balance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot balance metrics\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot MSE\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x='Method', y='MSE', hue='Misspecified', data=balance_df)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('MSE Evaluator')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend(title='Misspecified')\n",
    "\n",
    "# Plot LogLoss\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(x='Method', y='LogLoss', hue='Misspecified', data=balance_df)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('LogLoss Evaluator')\n",
    "plt.ylabel('LogLoss')\n",
    "plt.legend(title='Misspecified')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated the use of permutation weighting for causal inference using the Kang-Schafer simulation dataset. We've compared different classifiers (logistic regression, boosting, SGD, and neural networks) in both correctly specified and misspecified settings.\n",
    "\n",
    "Key observations:\n",
    "1. All methods perform well when the model is correctly specified.\n",
    "2. With misspecification, more flexible models like boosting and neural networks tend to perform better.\n",
    "3. Balance metrics (MSE and LogLoss) are predictive of causal estimation error.\n",
    "4. SGD-based methods provide comparable performance to their batch counterparts, which is promising for scalability to large datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
