{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved to: tuning_results/hyperparam_20250318_145409\n"
     ]
    }
   ],
   "source": [
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import os\n",
    "    from datetime import (datetime)\n",
    "    import json\n",
    "    import multiprocessing\n",
    "    #import sys\n",
    "    import itertools\n",
    "    import time\n",
    "    \n",
    "    import numpy as np\n",
    "\n",
    "    import concurrent.futures\n",
    "    from sklearn.model_selection import KFold\n",
    "    from permutation_weighting.estimator import PW\n",
    "    \n",
    "    # Ensure the examples directory is in the path\n",
    "    #sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "    \n",
    "    # Import from permutation_weighting\n",
    "    from permutation_weighting.estimator import PW\n",
    "    \n",
    "    # Import utilities from examples directory\n",
    "    from data_utils import generate_kang_schafer_data, evaluate_ate_binary, evaluate_dose_response_continuous\n",
    "    from plots import generate_model_performance_plots, improved_final_model_evaluation, create_timestamped_directory\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = create_timestamped_directory(base_dir=\"tuning_results\", prefix=\"hyperparam\")\n",
    "    print(f\"Results will be saved to: {output_dir}\")\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-18T13:54:09.290468Z",
     "start_time": "2025-03-18T13:54:08.398806Z"
    }
   },
   "id": "8d32ab7f51c57cc7",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define evaluate_params as a standalone function outside any other function\n",
    "def evaluate_params(params_tuple, X, A, df, cv_splits, method, n_replications, \n",
    "                   use_sgd, use_torch, true_ate_value, continuous_treatment, \n",
    "                   method_name, param_names, evaluate_ate_binary, evaluate_dose_response_continuous):\n",
    "    \"\"\"\n",
    "    Evaluate a single parameter combination across cross-validation folds\n",
    "    \"\"\"\n",
    "    idx, values = params_tuple\n",
    "    params = dict(zip(param_names, values))\n",
    "    \n",
    "    # Storage for fold results\n",
    "    fold_results = []\n",
    "    \n",
    "    # Run cross-validation\n",
    "    for fold, (train_idx, test_idx) in enumerate(cv_splits):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        A_train, A_test = A[train_idx], A[test_idx]\n",
    "        \n",
    "        # Create train dataframe for evaluation\n",
    "        df_train = pd.DataFrame({\n",
    "            **{f'X{i}': X_train[:, i] for i in range(X_train.shape[1])},\n",
    "            'A': A_train\n",
    "        })\n",
    "        \n",
    "        for col in df.columns:\n",
    "            if col.startswith('Y') or col == 'true_dr':\n",
    "                df_train[col] = df.loc[train_idx, col].values\n",
    "        \n",
    "        try:\n",
    "            # Determine batch_size if using SGD or torch\n",
    "            batch_size = None\n",
    "            if 'batch_size' in params:\n",
    "                batch_size = params['batch_size']\n",
    "            elif use_sgd or use_torch:\n",
    "                # Use a default batch size appropriate for the dataset size\n",
    "                batch_size = min(128, max(32, X_train.shape[0] // 10))\n",
    "            \n",
    "            # Train PW model\n",
    "            pw_result = PW(\n",
    "                A=A_train, \n",
    "                X=X_train, \n",
    "                classifier=method, \n",
    "                classifier_params=params,\n",
    "                estimand='ATE',\n",
    "                num_replicates=n_replications,\n",
    "                use_sgd=use_sgd,\n",
    "                use_torch=use_torch,\n",
    "                batch_size=batch_size\n",
    "            )\n",
    "            \n",
    "            # Save in-sample metrics\n",
    "            in_sample_mse = pw_result['train'].get('MSEEvaluator', np.nan)\n",
    "            in_sample_logloss = pw_result['train'].get('LogLossEvaluator', np.nan)\n",
    "            \n",
    "            # Apply to test set\n",
    "            eval_data = {'A': A_test, 'X': X_test}\n",
    "            eval_pw_result = PW(\n",
    "                A=A_train, \n",
    "                X=X_train, \n",
    "                classifier=method, \n",
    "                classifier_params=params,\n",
    "                estimand='ATE',\n",
    "                num_replicates=n_replications,\n",
    "                eval_data=eval_data,\n",
    "                use_sgd=use_sgd,\n",
    "                use_torch=use_torch,\n",
    "                batch_size=batch_size\n",
    "            )\n",
    "            \n",
    "            # Get out-of-sample metrics\n",
    "            out_sample_mse = eval_pw_result['eval'].get('MSEEvaluator', np.nan)\n",
    "            out_sample_logloss = eval_pw_result['eval'].get('LogLossEvaluator', np.nan)\n",
    "            \n",
    "            # Calculate error metric\n",
    "            if continuous_treatment:\n",
    "                # For continuous treatment\n",
    "                dr_eval = evaluate_dose_response_continuous(df_train, pw_result['weights'])\n",
    "                target_error = dr_eval['integrated_bias']\n",
    "            else:\n",
    "                # For binary treatment\n",
    "                est_ate = evaluate_ate_binary(df_train, pw_result['weights'], true_ate_value)\n",
    "                target_error = abs(est_ate)\n",
    "            \n",
    "            # Save result\n",
    "            fold_results.append({\n",
    "                'fold': fold,\n",
    "                'in_sample_mse': in_sample_mse,\n",
    "                'in_sample_logloss': in_sample_logloss,\n",
    "                'out_sample_mse': out_sample_mse,\n",
    "                'out_sample_logloss': out_sample_logloss,\n",
    "                'target_error': target_error,\n",
    "                'converged': pw_result.get('convergence_info', {}).get('converged', True)\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Silently continue on error\n",
    "            pass\n",
    "    \n",
    "    # Skip if no valid results\n",
    "    if not fold_results:\n",
    "        return None\n",
    "    \n",
    "    # Average results across folds\n",
    "    mean_results = {\n",
    "        k: np.mean([r[k] for r in fold_results if k in r and not np.isnan(r[k])]) \n",
    "        for k in ['in_sample_mse', 'in_sample_logloss', 'out_sample_mse', \n",
    "                  'out_sample_logloss', 'target_error']\n",
    "    }\n",
    "    \n",
    "    # Calculate standard errors\n",
    "    std_results = {\n",
    "        f\"{k}_std\": np.std([r[k] for r in fold_results if k in r and not np.isnan(r[k])]) / np.sqrt(len(fold_results))\n",
    "        for k in ['in_sample_mse', 'in_sample_logloss', 'out_sample_mse', \n",
    "                 'out_sample_logloss', 'target_error']\n",
    "    }\n",
    "    \n",
    "    # Save parameters\n",
    "    result = {**params, **mean_results, **std_results, 'method': method_name, 'params_idx': idx}\n",
    "    \n",
    "    # Convert any lists or tuples in params to strings for safe storage\n",
    "    for k, v in params.items():\n",
    "        if isinstance(v, (list, tuple)):\n",
    "            result[k] = str(v)\n",
    "    \n",
    "    return result\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-18T13:54:13.964716Z",
     "start_time": "2025-03-18T13:54:13.957971Z"
    }
   },
   "id": "3501b05d1d63dc52",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Modified cross_validate_hyperparams function that correctly passes parameters to evaluate_params\n",
    "def cross_validate_hyperparams(df, method, param_grid, method_name, n_folds=5, \n",
    "                             use_sgd=False, use_torch=False, \n",
    "                             n_replications=1, seed=42, verbose=True,\n",
    "                             max_workers=8, true_ate_value=None):\n",
    "    \"\"\"\n",
    "    Perform cross-validation to tune hyperparameters with parallel processing\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: pd.DataFrame\n",
    "        Data frame with columns: X1-X4, A, Y, Y1, Y0 (for binary) or true_dr (for continuous)\n",
    "    method: str\n",
    "        Classification method ('logit', 'boosting', 'neural_net', etc.)\n",
    "    param_grid: dict\n",
    "        Dictionary mapping parameter names to lists of values to try\n",
    "    method_name: str\n",
    "        Name to identify this method in results\n",
    "    n_folds: int\n",
    "        Number of cross-validation folds\n",
    "    use_sgd: bool\n",
    "        Whether to use SGD-based training\n",
    "    use_torch: bool\n",
    "        Whether to use PyTorch-based training\n",
    "    n_replications: int\n",
    "        Number of permutation replications for PW\n",
    "    seed: int\n",
    "        Random seed for reproducibility\n",
    "    verbose: bool\n",
    "        Whether to print progress information\n",
    "    max_workers: int\n",
    "        Maximum number of parallel workers\n",
    "    true_ate_value: float\n",
    "        True ATE value for evaluation (if None, will be calculated from data)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    results: pd.DataFrame\n",
    "        Data frame with results of cross-validation\n",
    "    \"\"\"\n",
    "    from data_utils import evaluate_ate_binary, evaluate_dose_response_continuous\n",
    "    \n",
    "    # Extract features and target\n",
    "    feature_cols = [col for col in df.columns if col.startswith('X') and not col.endswith('_mis')]\n",
    "    X = df[feature_cols].values\n",
    "    A = df['A'].values\n",
    "    \n",
    "    # Determine if treatment is continuous\n",
    "    continuous_treatment = 'true_dr' in df.columns\n",
    "    \n",
    "    # Set up cross-validation\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "    cv_splits = list(kf.split(X))\n",
    "    \n",
    "    # Set true target value for binary treatment\n",
    "    if not continuous_treatment:\n",
    "        if true_ate_value is None:\n",
    "            # Calculate from potential outcomes if available\n",
    "            if 'Y1' in df.columns and 'Y0' in df.columns:\n",
    "                true_ate_value = np.mean(df['Y1'] - df['Y0'])\n",
    "            else:\n",
    "                true_ate_value = 1.0  # Default value for Kang-Schafer simulation\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Using True ATE: {true_ate_value:.4f}\")\n",
    "    else:\n",
    "        true_ate_value = None\n",
    "    \n",
    "    # Generate all parameter combinations\n",
    "    param_names = list(param_grid.keys())\n",
    "    param_values = list(itertools.product(*param_grid.values()))\n",
    "    \n",
    "    # Progress tracking\n",
    "    total_combos = len(param_values)\n",
    "    if verbose:\n",
    "        print(f\"Running {total_combos} parameter combinations for {method_name} using up to {max_workers} workers...\")\n",
    "    \n",
    "    # Track time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Wrapper function to make it easier to call evaluate_params with all the needed parameters\n",
    "    def evaluate_params_wrapper(params_tuple):\n",
    "        return evaluate_params(\n",
    "            params_tuple=params_tuple,\n",
    "            X=X,\n",
    "            A=A,\n",
    "            df=df,\n",
    "            cv_splits=cv_splits,\n",
    "            method=method,\n",
    "            n_replications=n_replications,\n",
    "            use_sgd=use_sgd,\n",
    "            use_torch=use_torch,\n",
    "            true_ate_value=true_ate_value,\n",
    "            continuous_treatment=continuous_treatment,\n",
    "            method_name=method_name,\n",
    "            param_names=param_names,\n",
    "            evaluate_ate_binary=evaluate_ate_binary,\n",
    "            evaluate_dose_response_continuous=evaluate_dose_response_continuous\n",
    "        )\n",
    "    \n",
    "    # Run evaluations in parallel\n",
    "    results = []\n",
    "    \n",
    "    # Use ThreadPoolExecutor for macOS\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Map the parameters directly\n",
    "        futures = [executor.submit(evaluate_params_wrapper, (i, values)) \n",
    "                  for i, values in enumerate(param_values)]\n",
    "        \n",
    "        # Process results as they complete\n",
    "        for i, future in enumerate(concurrent.futures.as_completed(futures)):\n",
    "            if verbose and i % max(1, total_combos // 10) == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                print(f\"Processed {i+1}/{total_combos} combinations - Elapsed: {elapsed:.1f}s\")\n",
    "            \n",
    "            try:\n",
    "                result = future.result()\n",
    "                if result is not None:\n",
    "                    results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing result: {e}\")\n",
    "    \n",
    "    # Create DataFrame from results\n",
    "    df_results = pd.DataFrame([r for r in results if r is not None])\n",
    "    \n",
    "    # Sort by target error\n",
    "    if not df_results.empty:\n",
    "        df_results = df_results.sort_values('target_error')\n",
    "    \n",
    "    # Print best parameters\n",
    "    if verbose and not df_results.empty:\n",
    "        best_idx = df_results['target_error'].idxmin()\n",
    "        best_params = {k: df_results.loc[best_idx, k] for k in param_names}\n",
    "        print(f\"\\nBest parameters for {method_name}:\")\n",
    "        for k, v in best_params.items():\n",
    "            print(f\"  {k}: {v}\")\n",
    "        print(f\"Target Error: {df_results.loc[best_idx, 'target_error']:.4f}\")\n",
    "        print(f\"Out-of-sample Log Loss: {df_results.loc[best_idx, 'out_sample_logloss']:.4f}\")\n",
    "    \n",
    "    return df_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-18T13:54:16.281082Z",
     "start_time": "2025-03-18T13:54:16.275027Z"
    }
   },
   "id": "f186c36cda57f44c",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-18T13:54:17.449328Z",
     "start_time": "2025-03-18T13:54:17.447976Z"
    }
   },
   "id": "af6d1ff9361f8c5f",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-18T13:54:18.281469Z",
     "start_time": "2025-03-18T13:54:18.279988Z"
    }
   },
   "id": "6fd53046dfeb81ab",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Kang-Schafer data...\n",
      "Generated binary treatment data with 2000 observations\n",
      "True ATE: 0.9484\n",
      "PyTorch is available. Will include PyTorch models.\n",
      "Using 8 parallel workers for hyperparameter tuning\n",
      "\n",
      "=== Binary Treatment Hyperparameter Tuning ===\n",
      "\n",
      "Tuning Standard Logistic Regression...\n",
      "Using True ATE: 0.9484\n",
      "Running 12 parameter combinations for Standard Logistic using up to 8 workers...\n",
      "Processed 1/12 combinations - Elapsed: 1.9s\n",
      "Processed 2/12 combinations - Elapsed: 2.0s\n",
      "Processed 3/12 combinations - Elapsed: 2.0s\n",
      "Processed 4/12 combinations - Elapsed: 2.0s\n",
      "Processed 5/12 combinations - Elapsed: 2.2s\n",
      "Processed 6/12 combinations - Elapsed: 2.2s\n",
      "Processed 7/12 combinations - Elapsed: 2.4s\n",
      "Processed 8/12 combinations - Elapsed: 2.5s\n",
      "Processed 9/12 combinations - Elapsed: 3.0s\n",
      "Processed 10/12 combinations - Elapsed: 3.1s\n",
      "Processed 11/12 combinations - Elapsed: 3.1s\n",
      "Processed 12/12 combinations - Elapsed: 3.1s\n",
      "\n",
      "Best parameters for Standard Logistic:\n",
      "  C: 10.0\n",
      "  penalty: l2\n",
      "  solver: saga\n",
      "Target Error: 2.0644\n",
      "Out-of-sample Log Loss: 0.7226\n",
      "\n",
      "Tuning Gradient Boosting...\n",
      "Using True ATE: 0.9484\n",
      "Running 18 parameter combinations for Gradient Boosting using up to 8 workers...\n",
      "Processed 1/18 combinations - Elapsed: 4.6s\n",
      "Processed 2/18 combinations - Elapsed: 4.7s\n",
      "Processed 3/18 combinations - Elapsed: 6.3s\n",
      "Processed 4/18 combinations - Elapsed: 6.7s\n",
      "Processed 5/18 combinations - Elapsed: 8.6s\n",
      "Processed 6/18 combinations - Elapsed: 8.9s\n",
      "Processed 7/18 combinations - Elapsed: 10.0s\n",
      "Processed 8/18 combinations - Elapsed: 13.9s\n",
      "Processed 9/18 combinations - Elapsed: 15.4s\n",
      "Processed 10/18 combinations - Elapsed: 20.6s\n",
      "Processed 11/18 combinations - Elapsed: 23.9s\n",
      "Processed 12/18 combinations - Elapsed: 25.6s\n",
      "Processed 13/18 combinations - Elapsed: 29.4s\n",
      "Processed 14/18 combinations - Elapsed: 33.7s\n",
      "Processed 15/18 combinations - Elapsed: 36.0s\n",
      "Processed 16/18 combinations - Elapsed: 40.3s\n",
      "Processed 17/18 combinations - Elapsed: 42.4s\n",
      "Processed 18/18 combinations - Elapsed: 47.3s\n",
      "\n",
      "Best parameters for Gradient Boosting:\n",
      "  n_estimators: 200\n",
      "  learning_rate: 0.1\n",
      "  max_depth: 2\n",
      "Target Error: 4.5851\n",
      "Out-of-sample Log Loss: 0.7374\n",
      "\n",
      "Tuning SGD Logistic Regression...\n",
      "Using True ATE: 0.9484\n",
      "Running 81 parameter combinations for SGD Logistic using up to 8 workers...\n",
      "Processed 1/81 combinations - Elapsed: 0.0s\n",
      "Processed 9/81 combinations - Elapsed: 0.1s\n",
      "Processed 17/81 combinations - Elapsed: 0.1s\n",
      "Processed 25/81 combinations - Elapsed: 0.1s\n",
      "Processed 33/81 combinations - Elapsed: 0.2s\n",
      "Processed 41/81 combinations - Elapsed: 0.2s\n",
      "Processed 49/81 combinations - Elapsed: 0.3s\n",
      "Processed 57/81 combinations - Elapsed: 0.3s\n",
      "Processed 65/81 combinations - Elapsed: 0.3s\n",
      "Processed 73/81 combinations - Elapsed: 0.4s\n",
      "Processed 81/81 combinations - Elapsed: 0.4s\n",
      "\n",
      "Tuning Neural Network...\n",
      "Using True ATE: 0.9484\n",
      "Running 4 parameter combinations for Neural Network using up to 8 workers...\n",
      "Processed 1/4 combinations - Elapsed: 13.1s\n",
      "Processed 2/4 combinations - Elapsed: 18.9s\n",
      "Processed 3/4 combinations - Elapsed: 22.3s\n",
      "Processed 4/4 combinations - Elapsed: 25.4s\n",
      "\n",
      "Best parameters for Neural Network:\n",
      "  hidden_layer_sizes: (32,)\n",
      "  activation: relu\n",
      "  alpha: 0.001\n",
      "  learning_rate_init: 0.01\n",
      "  batch_size: 32\n",
      "  max_iter: 50\n",
      "  early_stopping: True\n",
      "  n_iter_no_change: 5\n",
      "Target Error: 16.2980\n",
      "Out-of-sample Log Loss: 0.6712\n",
      "\n",
      "Tuning PyTorch Logistic Regression...\n",
      "Using True ATE: 0.9484\n",
      "Running 8 parameter combinations for PyTorch Logistic using up to 8 workers...\n",
      "Processed 1/8 combinations - Elapsed: 15.3s\n",
      "Processed 2/8 combinations - Elapsed: 15.8s\n",
      "Processed 3/8 combinations - Elapsed: 16.1s\n",
      "Processed 4/8 combinations - Elapsed: 16.4s\n",
      "Processed 5/8 combinations - Elapsed: 17.8s\n",
      "Processed 6/8 combinations - Elapsed: 17.8s\n",
      "Processed 7/8 combinations - Elapsed: 18.0s\n",
      "Processed 8/8 combinations - Elapsed: 18.0s\n",
      "\n",
      "Best parameters for PyTorch Logistic:\n",
      "  learning_rate: 0.01\n",
      "  l2_reg: 0.001\n",
      "  batch_size: 64\n",
      "  max_iter: 100\n",
      "Target Error: 16.5353\n",
      "Out-of-sample Log Loss: 0.6931\n",
      "\n",
      "Tuning PyTorch MLP...\n",
      "Using True ATE: 0.9484\n",
      "Running 16 parameter combinations for PyTorch MLP using up to 8 workers...\n",
      "Processed 1/16 combinations - Elapsed: 19.2s\n",
      "Processed 2/16 combinations - Elapsed: 21.0s\n",
      "Processed 3/16 combinations - Elapsed: 34.2s\n",
      "Processed 4/16 combinations - Elapsed: 39.1s\n",
      "Processed 5/16 combinations - Elapsed: 40.2s\n",
      "Processed 6/16 combinations - Elapsed: 40.9s\n",
      "Processed 7/16 combinations - Elapsed: 58.9s\n",
      "Processed 8/16 combinations - Elapsed: 61.6s\n",
      "Processed 9/16 combinations - Elapsed: 62.5s\n",
      "Processed 10/16 combinations - Elapsed: 67.0s\n",
      "Processed 11/16 combinations - Elapsed: 78.3s\n",
      "Processed 12/16 combinations - Elapsed: 78.7s\n",
      "Processed 13/16 combinations - Elapsed: 81.1s\n",
      "Processed 14/16 combinations - Elapsed: 81.4s\n",
      "Processed 15/16 combinations - Elapsed: 82.2s\n",
      "Processed 16/16 combinations - Elapsed: 82.9s\n",
      "\n",
      "Best parameters for PyTorch MLP:\n",
      "  hidden_dims: [32, 16]\n",
      "  learning_rate: 0.001\n",
      "  l2_reg: 0.0001\n",
      "  batch_size: 64\n",
      "  max_iter: 100\n",
      "Target Error: 1.1285\n",
      "Out-of-sample Log Loss: 0.6763\n",
      "\n",
      "Generating performance plots...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Starting ROC curve evaluation for different models\n",
      "INFO: Processed methods for evaluation:\n",
      "INFO:   Standard Logistic: logit - {'C': np.float64(10.0), 'penalty': 'l2', 'solver': 'saga', 'max_iter': np.float64(nan), 'random_state': 42}\n",
      "INFO:   Gradient Boosting: boosting - {'n_estimators': np.float64(200.0), 'learning_rate': np.float64(0.1), 'max_depth': np.float64(2.0), 'random_state': 42}\n",
      "INFO:   Neural Network: neural_net - {'hidden_layer_sizes': (32,), 'activation': 'relu', 'alpha': np.float64(0.001), 'learning_rate_init': np.float64(0.01), 'batch_size': np.float64(32.0), 'max_iter': np.float64(50.0), 'early_stopping': True, 'n_iter_no_change': np.float64(5.0), 'random_state': 42}\n",
      "INFO:   PyTorch Logistic: logistic - {'learning_rate': np.float64(0.01), 'batch_size': np.float64(64.0), 'l2_reg': np.float64(0.001), 'hidden_dims': nan, 'random_state': 42}\n",
      "INFO:   PyTorch MLP: mlp - {'learning_rate': np.float64(0.001), 'batch_size': np.float64(64.0), 'l2_reg': np.float64(0.0001), 'hidden_dims': [32, 16], 'random_state': 42}\n",
      "INFO: Processing fold 1/10\n",
      "ERROR: Error with Standard Logistic in fold 0: The 'max_iter' parameter of LogisticRegression must be an int in the range [0, inf). Got np.float64(nan) instead.\n",
      "ERROR: Error with Gradient Boosting in fold 0: The 'max_depth' parameter of GradientBoostingClassifier must be an int in the range [1, inf) or None. Got np.float64(2.0) instead.\n",
      "ERROR: Error with Neural Network in fold 0: expected a sequence of integers or a single integer, got 'np.float64(32.0)'\n",
      "ERROR: Error with PyTorch Logistic in fold 0: expected a sequence of integers or a single integer, got 'np.float64(64.0)'\n",
      "ERROR: Error with PyTorch MLP in fold 0: expected a sequence of integers or a single integer, got 'np.float64(64.0)'\n",
      "INFO: Processing fold 2/10\n",
      "ERROR: Error with Standard Logistic in fold 1: The 'max_iter' parameter of LogisticRegression must be an int in the range [0, inf). Got np.float64(nan) instead.\n",
      "ERROR: Error with Gradient Boosting in fold 1: The 'max_depth' parameter of GradientBoostingClassifier must be an int in the range [1, inf) or None. Got np.float64(2.0) instead.\n",
      "ERROR: Error with Neural Network in fold 1: expected a sequence of integers or a single integer, got 'np.float64(32.0)'\n",
      "ERROR: Error with PyTorch Logistic in fold 1: expected a sequence of integers or a single integer, got 'np.float64(64.0)'\n",
      "ERROR: Error with PyTorch MLP in fold 1: expected a sequence of integers or a single integer, got 'np.float64(64.0)'\n",
      "INFO: Processing fold 3/10\n",
      "ERROR: Error with Standard Logistic in fold 2: The 'max_iter' parameter of LogisticRegression must be an int in the range [0, inf). Got np.float64(nan) instead.\n",
      "ERROR: Error with Gradient Boosting in fold 2: The 'max_depth' parameter of GradientBoostingClassifier must be an int in the range [1, inf) or None. Got np.float64(2.0) instead.\n",
      "ERROR: Error with Neural Network in fold 2: expected a sequence of integers or a single integer, got 'np.float64(32.0)'\n",
      "ERROR: Error with PyTorch Logistic in fold 2: expected a sequence of integers or a single integer, got 'np.float64(64.0)'\n",
      "ERROR: Error with PyTorch MLP in fold 2: expected a sequence of integers or a single integer, got 'np.float64(64.0)'\n",
      "INFO: Processing fold 4/10\n",
      "ERROR: Error with Standard Logistic in fold 3: The 'max_iter' parameter of LogisticRegression must be an int in the range [0, inf). Got np.float64(nan) instead.\n",
      "ERROR: Error with Gradient Boosting in fold 3: The 'max_depth' parameter of GradientBoostingClassifier must be an int in the range [1, inf) or None. Got np.float64(2.0) instead.\n",
      "ERROR: Error with Neural Network in fold 3: expected a sequence of integers or a single integer, got 'np.float64(32.0)'\n",
      "ERROR: Error with PyTorch Logistic in fold 3: expected a sequence of integers or a single integer, got 'np.float64(64.0)'\n",
      "ERROR: Error with PyTorch MLP in fold 3: expected a sequence of integers or a single integer, got 'np.float64(64.0)'\n",
      "INFO: Processing fold 5/10\n",
      "ERROR: Error with Standard Logistic in fold 4: The 'max_iter' parameter of LogisticRegression must be an int in the range [0, inf). Got np.float64(nan) instead.\n",
      "ERROR: Error with Gradient Boosting in fold 4: The 'max_depth' parameter of GradientBoostingClassifier must be an int in the range [1, inf) or None. Got np.float64(2.0) instead.\n",
      "ERROR: Error with Neural Network in fold 4: expected a sequence of integers or a single integer, got 'np.float64(32.0)'\n",
      "ERROR: Error with PyTorch Logistic in fold 4: expected a sequence of integers or a single integer, got 'np.float64(64.0)'\n",
      "ERROR: Error with PyTorch MLP in fold 4: expected a sequence of integers or a single integer, got 'np.float64(64.0)'\n",
      "INFO: Processing fold 6/10\n",
      "ERROR: Error with Standard Logistic in fold 5: The 'max_iter' parameter of LogisticRegression must be an int in the range [0, inf). Got np.float64(nan) instead.\n",
      "ERROR: Error with Gradient Boosting in fold 5: The 'max_depth' parameter of GradientBoostingClassifier must be an int in the range [1, inf) or None. Got np.float64(2.0) instead.\n",
      "ERROR: Error with Neural Network in fold 5: expected a sequence of integers or a single integer, got 'np.float64(32.0)'\n",
      "ERROR: Error with PyTorch Logistic in fold 5: expected a sequence of integers or a single integer, got 'np.float64(64.0)'\n",
      "ERROR: Error with PyTorch MLP in fold 5: expected a sequence of integers or a single integer, got 'np.float64(64.0)'\n",
      "INFO: Processing fold 7/10\n",
      "ERROR: Error with Standard Logistic in fold 6: The 'max_iter' parameter of LogisticRegression must be an int in the range [0, inf). Got np.float64(nan) instead.\n",
      "ERROR: Error with Gradient Boosting in fold 6: The 'max_depth' parameter of GradientBoostingClassifier must be an int in the range [1, inf) or None. Got np.float64(2.0) instead.\n",
      "ERROR: Error with Neural Network in fold 6: expected a sequence of integers or a single integer, got 'np.float64(32.0)'\n",
      "ERROR: Error with PyTorch Logistic in fold 6: expected a sequence of integers or a single integer, got 'np.float64(64.0)'\n",
      "ERROR: Error with PyTorch MLP in fold 6: expected a sequence of integers or a single integer, got 'np.float64(64.0)'\n",
      "INFO: Processing fold 8/10\n",
      "ERROR: Error with Standard Logistic in fold 7: The 'max_iter' parameter of LogisticRegression must be an int in the range [0, inf). Got np.float64(nan) instead.\n",
      "ERROR: Error with Gradient Boosting in fold 7: The 'max_depth' parameter of GradientBoostingClassifier must be an int in the range [1, inf) or None. Got np.float64(2.0) instead.\n",
      "ERROR: Error with Neural Network in fold 7: expected a sequence of integers or a single integer, got 'np.float64(32.0)'\n",
      "ERROR: Error with PyTorch Logistic in fold 7: expected a sequence of integers or a single integer, got 'np.float64(64.0)'\n",
      "ERROR: Error with PyTorch MLP in fold 7: expected a sequence of integers or a single integer, got 'np.float64(64.0)'\n",
      "INFO: Processing fold 9/10\n",
      "ERROR: Error with Standard Logistic in fold 8: The 'max_iter' parameter of LogisticRegression must be an int in the range [0, inf). Got np.float64(nan) instead.\n",
      "ERROR: Error with Gradient Boosting in fold 8: The 'max_depth' parameter of GradientBoostingClassifier must be an int in the range [1, inf) or None. Got np.float64(2.0) instead.\n",
      "ERROR: Error with Neural Network in fold 8: expected a sequence of integers or a single integer, got 'np.float64(32.0)'\n",
      "ERROR: Error with PyTorch Logistic in fold 8: expected a sequence of integers or a single integer, got 'np.float64(64.0)'\n",
      "ERROR: Error with PyTorch MLP in fold 8: expected a sequence of integers or a single integer, got 'np.float64(64.0)'\n",
      "INFO: Processing fold 10/10\n",
      "ERROR: Error with Standard Logistic in fold 9: The 'max_iter' parameter of LogisticRegression must be an int in the range [0, inf). Got np.float64(nan) instead.\n",
      "ERROR: Error with Gradient Boosting in fold 9: The 'max_depth' parameter of GradientBoostingClassifier must be an int in the range [1, inf) or None. Got np.float64(2.0) instead.\n",
      "ERROR: Error with Neural Network in fold 9: expected a sequence of integers or a single integer, got 'np.float64(32.0)'\n",
      "ERROR: Error with PyTorch Logistic in fold 9: expected a sequence of integers or a single integer, got 'np.float64(64.0)'\n",
      "ERROR: Error with PyTorch MLP in fold 9: expected a sequence of integers or a single integer, got 'np.float64(64.0)'\n",
      "WARNING: No valid ROC results for Standard Logistic\n",
      "WARNING: No valid ROC results for Gradient Boosting\n",
      "WARNING: No valid ROC results for Neural Network\n",
      "WARNING: No valid ROC results for PyTorch Logistic\n",
      "WARNING: No valid ROC results for PyTorch MLP\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best configuration for each method:\n",
      "Standard Logistic:\n",
      "  ATE Error: 2.0644\n",
      "  In-sample Log Loss: 0.7262\n",
      "  Out-of-sample Log Loss: 0.7226\n",
      "  Parameters:\n",
      "    C: 10.0\n",
      "    penalty: l2\n",
      "    solver: saga\n",
      "    params_idx: 10\n",
      "    n_estimators: nan\n",
      "    learning_rate: nan\n",
      "    max_depth: nan\n",
      "    hidden_layer_sizes: nan\n",
      "    activation: nan\n",
      "    alpha: nan\n",
      "    learning_rate_init: nan\n",
      "    batch_size: nan\n",
      "    max_iter: nan\n",
      "    early_stopping: nan\n",
      "    n_iter_no_change: nan\n",
      "    l2_reg: nan\n",
      "    hidden_dims: nan\n",
      "\n",
      "Gradient Boosting:\n",
      "  ATE Error: 4.5851\n",
      "  In-sample Log Loss: 0.7105\n",
      "  Out-of-sample Log Loss: 0.7374\n",
      "  Parameters:\n",
      "    C: nan\n",
      "    penalty: nan\n",
      "    solver: nan\n",
      "    params_idx: 15\n",
      "    n_estimators: 200.0\n",
      "    learning_rate: 0.1\n",
      "    max_depth: 2.0\n",
      "    hidden_layer_sizes: nan\n",
      "    activation: nan\n",
      "    alpha: nan\n",
      "    learning_rate_init: nan\n",
      "    batch_size: nan\n",
      "    max_iter: nan\n",
      "    early_stopping: nan\n",
      "    n_iter_no_change: nan\n",
      "    l2_reg: nan\n",
      "    hidden_dims: nan\n",
      "\n",
      "Neural Network:\n",
      "  ATE Error: 16.2980\n",
      "  In-sample Log Loss: 0.6695\n",
      "  Out-of-sample Log Loss: 0.6712\n",
      "  Parameters:\n",
      "    C: nan\n",
      "    penalty: nan\n",
      "    solver: nan\n",
      "    params_idx: 0\n",
      "    n_estimators: nan\n",
      "    learning_rate: nan\n",
      "    max_depth: nan\n",
      "    hidden_layer_sizes: (32,)\n",
      "    activation: relu\n",
      "    alpha: 0.001\n",
      "    learning_rate_init: 0.01\n",
      "    batch_size: 32.0\n",
      "    max_iter: 50.0\n",
      "    early_stopping: True\n",
      "    n_iter_no_change: 5.0\n",
      "    l2_reg: nan\n",
      "    hidden_dims: nan\n",
      "\n",
      "PyTorch Logistic:\n",
      "  ATE Error: 16.5353\n",
      "  In-sample Log Loss: 0.6931\n",
      "  Out-of-sample Log Loss: 0.6931\n",
      "  Parameters:\n",
      "    C: nan\n",
      "    penalty: nan\n",
      "    solver: nan\n",
      "    params_idx: 0\n",
      "    n_estimators: nan\n",
      "    learning_rate: 0.01\n",
      "    max_depth: nan\n",
      "    hidden_layer_sizes: nan\n",
      "    activation: nan\n",
      "    alpha: nan\n",
      "    learning_rate_init: nan\n",
      "    batch_size: 64.0\n",
      "    max_iter: 100.0\n",
      "    early_stopping: nan\n",
      "    n_iter_no_change: nan\n",
      "    l2_reg: 0.001\n",
      "    hidden_dims: nan\n",
      "\n",
      "PyTorch MLP:\n",
      "  ATE Error: 1.1285\n",
      "  In-sample Log Loss: 0.6660\n",
      "  Out-of-sample Log Loss: 0.6763\n",
      "  Parameters:\n",
      "    C: nan\n",
      "    penalty: nan\n",
      "    solver: nan\n",
      "    params_idx: 8\n",
      "    n_estimators: nan\n",
      "    learning_rate: 0.001\n",
      "    max_depth: nan\n",
      "    hidden_layer_sizes: nan\n",
      "    activation: nan\n",
      "    alpha: nan\n",
      "    learning_rate_init: nan\n",
      "    batch_size: 64.0\n",
      "    max_iter: 100.0\n",
      "    early_stopping: nan\n",
      "    n_iter_no_change: nan\n",
      "    l2_reg: 0.0001\n",
      "    hidden_dims: [32, 16]\n",
      "\n",
      "Successfully generated performance plots in tuning_results/hyperparam_20250318_145409\n",
      "\n",
      "Running final model evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johannesmuller/Documents/github/permutation_weighting/examples/plots.py:937: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend(loc=\"lower right\", fontsize=12)\n",
      "INFO: ROC curves saved to tuning_results/hyperparam_20250318_145409/roc_curves.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hyperparameter tuning complete. Results saved to 'tuning_results/hyperparam_20250318_145409' directory.\n"
     ]
    }
   ],
   "source": [
    "# Main function for hyperparameter tuning notebook\n",
    "def main_hyperparameter_tuning():\n",
    "    \"\"\"\n",
    "    Main function to run hyperparameter tuning for permutation weighting methods\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate Kang-Schafer data for tuning\n",
    "    print(\"Generating Kang-Schafer data...\")\n",
    "    n_samples = 2000  # Adjust based on your needs\n",
    "    n_folds=5 # Adjust based on your needs\n",
    "    df_binary = generate_kang_schafer_data(n=n_samples, seed=42, misspecified=False, continuous_treatment=False)\n",
    "    print(f\"Generated binary treatment data with {n_samples} observations\")\n",
    "    \n",
    "    # Calculate true ATE manually if not available in data_utils\n",
    "    def calculate_true_ate(df):\n",
    "        \"\"\"Calculate true ATE from potential outcomes\"\"\"\n",
    "        if 'Y1' in df.columns and 'Y0' in df.columns:\n",
    "            return np.mean(df['Y1'] - df['Y0'])\n",
    "        return 1.0  # Default value for Kang-Schafer simulation\n",
    "    \n",
    "    true_ate_value = calculate_true_ate(df_binary)\n",
    "    print(f\"True ATE: {true_ate_value:.4f}\")\n",
    "    \n",
    "    # Define parameter grids\n",
    "    # Traditional methods\n",
    "    logit_params = {\n",
    "        'C': [0.1, 1.0, 10.0],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['saga', 'liblinear']\n",
    "    }\n",
    "    \n",
    "    boosting_params = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'max_depth': [2, 3, 4]\n",
    "    }\n",
    "    \n",
    "    # SGD-based methods with batch size for internal mini-batch optimization\n",
    "    sgd_logit_params = {\n",
    "        'alpha': [0.0001, 0.001, 0.01],\n",
    "        'learning_rate': ['constant', 'optimal', 'adaptive'],\n",
    "        'eta0': [0.001, 0.01, 0.1],\n",
    "        'batch_size': [32, 64, 128]  # Used for internal mini-batch optimization\n",
    "    }\n",
    "    \n",
    "    # neural_net_params = {\n",
    "    #     'hidden_layer_sizes': [(32,), (64,), (32, 16)],\n",
    "    #     'activation': ['relu', 'tanh'],\n",
    "    #     'alpha': [0.0001, 0.001],\n",
    "    #     'learning_rate_init': [0.001, 0.01],\n",
    "    #     'batch_size': [32, 64, 128]  # Used for internal mini-batch optimization\n",
    "    # }\n",
    "    \n",
    "    # Reduced neural net parameters\n",
    "    neural_net_params = {\n",
    "        'hidden_layer_sizes': [(32,), (64,)],  # Reduced from 3 to 2 options\n",
    "        'activation': ['relu'],  # Reduced from 2 to 1 option \n",
    "        'alpha': [0.001],  # Reduced from 2 to 1 option\n",
    "        'learning_rate_init': [0.01],  # Reduced from 2 to 1 option\n",
    "        'batch_size': [32, 64] ,\n",
    "        'max_iter': [50],\n",
    "        'early_stopping': [True],\n",
    "        'n_iter_no_change': [5]# Reduced from 3 to 2 options\n",
    "    }\n",
    "    \n",
    "    # PyTorch-based methods (if available)\n",
    "    torch_available = False\n",
    "    try:\n",
    "        import torch\n",
    "        torch_available = True\n",
    "        \n",
    "        torch_logistic_params = {\n",
    "            'learning_rate': [0.01, 0.1], #0.001,\n",
    "            'l2_reg': [ 0.001, 0.01], #0.0001,\n",
    "            'batch_size': [ 64, 128], #32,\n",
    "            'max_iter': [100],# Used for internal mini-batch optimization\n",
    "        }\n",
    "        \n",
    "        torch_mlp_params = {\n",
    "            'hidden_dims': [[32],[32, 16]], #[64],\n",
    "            'learning_rate': [0.001, 0.01],\n",
    "            'l2_reg': [0.0001, 0.001],\n",
    "            'batch_size': [64, 128], #32, \n",
    "            'max_iter': [100],# Used for internal mini-batch optimization\n",
    "        }\n",
    "        \n",
    "        print(\"PyTorch is available. Will include PyTorch models.\")\n",
    "    except ImportError:\n",
    "        print(\"PyTorch not available, skipping PyTorch-based models\")\n",
    "    \n",
    "  \n",
    "\n",
    "    \n",
    "    # Import necessary modules\n",
    "    import itertools\n",
    "    import time\n",
    "    \n",
    "    # Determine max workers based on system - use fewer than total cores for stability\n",
    "    max_workers = max(1, min(8, multiprocessing.cpu_count() - 1))\n",
    "    print(f\"Using {max_workers} parallel workers for hyperparameter tuning\")\n",
    "    \n",
    "    # Run hyperparameter tuning for binary treatment\n",
    "    print(\"\\n=== Binary Treatment Hyperparameter Tuning ===\")\n",
    "    \n",
    "    binary_results = {}\n",
    "    \n",
    "    # Standard logistic regression\n",
    "    print(\"\\nTuning Standard Logistic Regression...\")\n",
    "    binary_results['Standard Logistic'] = cross_validate_hyperparams(\n",
    "        df_binary, 'logit', logit_params, 'Standard Logistic',\n",
    "        n_folds=n_folds, max_workers=max_workers, true_ate_value=true_ate_value\n",
    "    )\n",
    "    \n",
    "    # Gradient boosting\n",
    "    print(\"\\nTuning Gradient Boosting...\")\n",
    "    binary_results['Gradient Boosting'] = cross_validate_hyperparams(\n",
    "        df_binary, 'boosting', boosting_params, 'Gradient Boosting',\n",
    "        n_folds=n_folds, max_workers=max_workers, true_ate_value=true_ate_value\n",
    "    )\n",
    "    \n",
    "    # SGD logistic regression\n",
    "    print(\"\\nTuning SGD Logistic Regression...\")\n",
    "    binary_results['SGD Logistic'] = cross_validate_hyperparams(\n",
    "        df_binary, 'logit', sgd_logit_params, 'SGD Logistic',\n",
    "        n_folds=n_folds, use_sgd=True, max_workers=max_workers, true_ate_value=true_ate_value\n",
    "    )\n",
    "    \n",
    "    # Neural network\n",
    "    print(\"\\nTuning Neural Network...\")\n",
    "    binary_results['Neural Network'] = cross_validate_hyperparams(\n",
    "        df_binary, 'neural_net', neural_net_params, 'Neural Network',\n",
    "        n_folds=n_folds, use_sgd=True, max_workers=max_workers, true_ate_value=true_ate_value\n",
    "    )\n",
    "    \n",
    "    # PyTorch models (if available)\n",
    "    if torch_available:\n",
    "        print(\"\\nTuning PyTorch Logistic Regression...\")\n",
    "        binary_results['PyTorch Logistic'] = cross_validate_hyperparams(\n",
    "            df_binary, 'logistic', torch_logistic_params, 'PyTorch Logistic',\n",
    "            n_folds=n_folds, use_torch=True, max_workers=max_workers, true_ate_value=true_ate_value\n",
    "        )\n",
    "        \n",
    "        print(\"\\nTuning PyTorch MLP...\")\n",
    "        binary_results['PyTorch MLP'] = cross_validate_hyperparams(\n",
    "            df_binary, 'mlp', torch_mlp_params, 'PyTorch MLP',\n",
    "            n_folds=n_folds, use_torch=True, max_workers=max_workers, true_ate_value=true_ate_value\n",
    "        )\n",
    "    \n",
    "    # Generate combined performance plots\n",
    "    # Add this to your main_hyperparameter_tuning function before calling generate_model_performance_plots\n",
    "    print(\"\\nGenerating performance plots...\")\n",
    "    \n",
    "    # Rename the column to match what generate_model_performance_plots expects\n",
    "    for method in binary_results:\n",
    "        if not binary_results[method].empty and 'target_error' in binary_results[method].columns:\n",
    "            # Rename 'target_error' to 'ate_error'\n",
    "            binary_results[method] = binary_results[method].rename(columns={\n",
    "                'target_error': 'ate_error', \n",
    "                'target_error_std': 'ate_error_std'\n",
    "        })\n",
    "\n",
    "    try:\n",
    "        best_configs = generate_model_performance_plots(binary_results, output_dir)\n",
    "        print(f\"Successfully generated performance plots in {output_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating performance plots: {str(e)}\")\n",
    "        # Create a simplified version of the best configs manually\n",
    "        best_configs = {}\n",
    "        for method_name, df in binary_results.items():\n",
    "            if not df.empty:\n",
    "                error_col = 'ate_error' if 'ate_error' in df.columns else 'target_error'\n",
    "                if error_col in df.columns:\n",
    "                    best_idx = df[error_col].idxmin()\n",
    "                    param_cols = [col for col in df.columns if col not in \n",
    "                                 ['method', 'ate_error', 'target_error', 'in_sample_mse', 'in_sample_logloss', \n",
    "                                  'out_sample_mse', 'out_sample_logloss', \n",
    "                                  'in_sample_mse_std', 'in_sample_logloss_std',\n",
    "                                  'out_sample_mse_std', 'out_sample_logloss_std', \n",
    "                                  'ate_error_std', 'target_error_std']]\n",
    "                    \n",
    "                    best_configs[method_name] = {\n",
    "                        'method': method_name,\n",
    "                        'params': {col: df.loc[best_idx, col] for col in param_cols},\n",
    "                        'ate_error': df.loc[best_idx, error_col],\n",
    "                        'in_sample_logloss': df.loc[best_idx, 'in_sample_logloss'] if 'in_sample_logloss' in df else None,\n",
    "                        'out_sample_logloss': df.loc[best_idx, 'out_sample_logloss'] if 'out_sample_logloss' in df else None\n",
    "                    }\n",
    "    \n",
    "    # Run final model evaluation with ROC curves\n",
    "    print(\"\\nRunning final model evaluation...\")\n",
    "    methods_to_eval = []\n",
    "    for method_name, best_config in best_configs.items():\n",
    "        # Extract parameters for this method\n",
    "        params = {k: v for k, v in best_config.items() \n",
    "                 if k not in ['ate_error', 'in_sample_logloss', 'out_sample_logloss', 'target_error', 'method']}\n",
    "        \n",
    "        # Determine which base method to use\n",
    "        use_sgd = False\n",
    "        use_torch = False\n",
    "        \n",
    "        if method_name == 'SGD Logistic' or method_name == 'Neural Network':\n",
    "            use_sgd = True\n",
    "            base_method = 'logit' if method_name == 'SGD Logistic' else 'neural_net'\n",
    "        elif method_name == 'PyTorch Logistic' or method_name == 'PyTorch MLP':\n",
    "            use_torch = True\n",
    "            base_method = 'logistic' if method_name == 'PyTorch Logistic' else 'mlp'\n",
    "        elif method_name == 'Gradient Boosting':\n",
    "            base_method = 'boosting'\n",
    "        else:  # Standard Logistic\n",
    "            base_method = 'logit'\n",
    "        \n",
    "        methods_to_eval.append((\n",
    "            method_name,\n",
    "            {'method': base_method, 'params': params, 'use_sgd': use_sgd, 'use_torch': use_torch}\n",
    "        ))\n",
    "    \n",
    "    # Generate ROC curves\n",
    "    improved_final_model_evaluation(df_binary, methods_to_eval, output_dir=output_dir)\n",
    "    \n",
    "    print(f\"\\nHyperparameter tuning complete. Results saved to '{output_dir}' directory.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_hyperparameter_tuning()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-18T13:57:19.068655Z",
     "start_time": "2025-03-18T13:54:19.657413Z"
    }
   },
   "id": "18b45874c548db85",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fce8f2c6874f812f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9b461346e2327e5b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1dd3cd1b79a2487c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Function to evaluate one parameter combination\n",
    "def evaluate_params(params_tuple):\n",
    "    idx, values = params_tuple\n",
    "    params = dict(zip(param_names, values))\n",
    "    \n",
    "    # Storage for fold results\n",
    "    fold_results = []\n",
    "    \n",
    "    # Run cross-validation\n",
    "    for fold, (train_idx, test_idx) in enumerate(cv_splits):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        A_train, A_test = A[train_idx], A[test_idx]\n",
    "        \n",
    "        # Create train dataframe for evaluation\n",
    "        df_train = pd.DataFrame({\n",
    "            **{f'X{i}': X_train[:, i] for i in range(X_train.shape[1])},\n",
    "            'A': A_train\n",
    "        })\n",
    "        \n",
    "        for col in df.columns:\n",
    "            if col.startswith('Y') or col == 'true_dr':\n",
    "                df_train[col] = df.loc[train_idx, col].values\n",
    "        \n",
    "        try:\n",
    "            # Determine batch_size if using SGD or torch\n",
    "            batch_size = None\n",
    "            if 'batch_size' in params:\n",
    "                batch_size = params['batch_size']\n",
    "            elif use_sgd or use_torch:\n",
    "                # Use a default batch size appropriate for the dataset size\n",
    "                batch_size = min(128, max(32, X_train.shape[0] // 10))\n",
    "            \n",
    "            # Train PW model\n",
    "            pw_result = PW(\n",
    "                A=A_train, \n",
    "                X=X_train, \n",
    "                classifier=method, \n",
    "                classifier_params=params,\n",
    "                estimand='ATE',\n",
    "                num_replicates=n_replications,\n",
    "                use_sgd=use_sgd,\n",
    "                use_torch=use_torch,\n",
    "                batch_size=batch_size\n",
    "            )\n",
    "            \n",
    "            # Save in-sample metrics\n",
    "            in_sample_mse = pw_result['train'].get('MSEEvaluator', np.nan)\n",
    "            in_sample_logloss = pw_result['train'].get('LogLossEvaluator', np.nan)\n",
    "            \n",
    "            # Apply to test set\n",
    "            eval_data = {'A': A_test, 'X': X_test}\n",
    "            eval_pw_result = PW(\n",
    "                A=A_train, \n",
    "                X=X_train, \n",
    "                classifier=method, \n",
    "                classifier_params=params,\n",
    "                estimand='ATE',\n",
    "                num_replicates=n_replications,\n",
    "                eval_data=eval_data,\n",
    "                use_sgd=use_sgd,\n",
    "                use_torch=use_torch,\n",
    "                batch_size=batch_size\n",
    "            )\n",
    "            \n",
    "            # Get out-of-sample metrics\n",
    "            out_sample_mse = eval_pw_result['eval'].get('MSEEvaluator', np.nan)\n",
    "            out_sample_logloss = eval_pw_result['eval'].get('LogLossEvaluator', np.nan)\n",
    "            \n",
    "            # Calculate error metric\n",
    "            if continuous_treatment:\n",
    "                # For continuous treatment\n",
    "                dr_eval = evaluate_dose_response_continuous(df_train, pw_result['weights'])\n",
    "                target_error = dr_eval['integrated_bias']\n",
    "            else:\n",
    "                # For binary treatment\n",
    "                est_ate = evaluate_ate_binary(df_train, pw_result['weights'], true_ate_value)\n",
    "                target_error = abs(est_ate)\n",
    "            \n",
    "            # Save result\n",
    "            fold_results.append({\n",
    "                'fold': fold,\n",
    "                'in_sample_mse': in_sample_mse,\n",
    "                'in_sample_logloss': in_sample_logloss,\n",
    "                'out_sample_mse': out_sample_mse,\n",
    "                'out_sample_logloss': out_sample_logloss,\n",
    "                'target_error': target_error,\n",
    "                'converged': pw_result.get('convergence_info', {}).get('converged', True)\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Silently continue on error\n",
    "            pass\n",
    "    \n",
    "    # Skip if no valid results\n",
    "    if not fold_results:\n",
    "        return None\n",
    "    \n",
    "    # Average results across folds\n",
    "    mean_results = {\n",
    "        k: np.mean([r[k] for r in fold_results if k in r and not np.isnan(r[k])]) \n",
    "        for k in ['in_sample_mse', 'in_sample_logloss', 'out_sample_mse', \n",
    "                  'out_sample_logloss', 'target_error']\n",
    "    }\n",
    "    \n",
    "    # Calculate standard errors\n",
    "    std_results = {\n",
    "        f\"{k}_std\": np.std([r[k] for r in fold_results if k in r and not np.isnan(r[k])]) / np.sqrt(len(fold_results))\n",
    "        for k in ['in_sample_mse', 'in_sample_logloss', 'out_sample_mse', \n",
    "                 'out_sample_logloss', 'target_error']\n",
    "    }\n",
    "    \n",
    "    # Save parameters\n",
    "    result = {**params, **mean_results, **std_results, 'method': method_name, 'params_idx': idx}\n",
    "    \n",
    "    # Convert any lists or tuples in params to strings for safe storage\n",
    "    for k, v in params.items():\n",
    "        if isinstance(v, (list, tuple)):\n",
    "            result[k] = str(v)\n",
    "\n",
    "    return result\n",
    "\n",
    "     # Function for cross validation that accepts true_ate_value parameter\n",
    "def cross_validate_hyperparams(df, method, param_grid, method_name, n_folds=n_folds, \n",
    "                             use_sgd=False, use_torch=False, \n",
    "                             n_replications=1, seed=42, verbose=True,\n",
    "                             max_workers=8, true_ate_value=None):\n",
    "    \"\"\"\n",
    "    Perform cross-validation to tune hyperparameters with parallel processing\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: pd.DataFrame\n",
    "        Data frame with columns: X1-X4, A, Y, Y1, Y0 (for binary) or true_dr (for continuous)\n",
    "    method: str\n",
    "        Classification method ('logit', 'boosting', 'neural_net', etc.)\n",
    "    param_grid: dict\n",
    "        Dictionary mapping parameter names to lists of values to try\n",
    "    method_name: str\n",
    "        Name to identify this method in results\n",
    "    n_folds: int\n",
    "        Number of cross-validation folds\n",
    "    use_sgd: bool\n",
    "        Whether to use SGD-based training\n",
    "    use_torch: bool\n",
    "        Whether to use PyTorch-based training\n",
    "    n_replications: int\n",
    "        Number of permutation replications for PW\n",
    "    seed: int\n",
    "        Random seed for reproducibility\n",
    "    verbose: bool\n",
    "        Whether to print progress information\n",
    "    max_workers: int\n",
    "        Maximum number of parallel workers\n",
    "    true_ate_value: float\n",
    "        True ATE value for evaluation (if None, will be calculated from data)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    results: pd.DataFrame\n",
    "        Data frame with results of cross-validation\n",
    "    \"\"\"\n",
    "    import concurrent.futures\n",
    "    \n",
    "    # Extract features and target\n",
    "    feature_cols = [col for col in df.columns if col.startswith('X') and not col.endswith('_mis')]\n",
    "    X = df[feature_cols].values\n",
    "    A = df['A'].values\n",
    "    \n",
    "    # Determine if treatment is continuous\n",
    "    \n",
    "    continuous_treatment = 'true_dr' in df.columns\n",
    "    \n",
    "    # Set up cross-validation\n",
    "    from sklearn.model_selection import KFold\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "    cv_splits = list(kf.split(X))\n",
    "    \n",
    "    # Set true target value for binary treatment\n",
    "    if not continuous_treatment:\n",
    "        if true_ate_value is None:\n",
    "            # Calculate from potential outcomes if available\n",
    "            if 'Y1' in df.columns and 'Y0' in df.columns:\n",
    "                true_ate_value = np.mean(df['Y1'] - df['Y0'])\n",
    "            else:\n",
    "                true_ate_value = 1.0  # Default value for Kang-Schafer simulation\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Using True ATE: {true_ate_value:.4f}\")\n",
    "    else:\n",
    "        true_ate_value = None\n",
    "    \n",
    "    # Generate all parameter combinations\n",
    "    param_names = list(param_grid.keys())\n",
    "    param_values = list(itertools.product(*param_grid.values()))\n",
    "    \n",
    "    # Progress tracking\n",
    "    total_combos = len(param_values)\n",
    "    if verbose:\n",
    "        print(f\"Running {total_combos} parameter combinations for {method_name} using up to {max_workers} workers...\")\n",
    "    \n",
    "    # Track time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    \n",
    "    # Run evaluations in parallel\n",
    "    results = []\n",
    "    \n",
    "    # Use ThreadPoolExecutor for better performance with numerical computations\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [executor.submit(evaluate_params, (i, values)) for i, values in enumerate(param_values)]\n",
    "        \n",
    "        # Process results as they complete\n",
    "        for i, future in enumerate(concurrent.futures.as_completed(futures)):\n",
    "            if verbose and i % max(1, total_combos // 10) == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                print(f\"Processed {i+1}/{total_combos} combinations - Elapsed: {elapsed:.1f}s\")\n",
    "            \n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                results.append(result)\n",
    "    \n",
    "    # Create DataFrame from results\n",
    "    df_results = pd.DataFrame([r for r in results if r is not None])\n",
    "    \n",
    "    # Sort by target error\n",
    "    if not df_results.empty:\n",
    "        df_results = df_results.sort_values('target_error')\n",
    "    \n",
    "    # Print best parameters\n",
    "    if verbose and not df_results.empty:\n",
    "        best_idx = df_results['target_error'].idxmin()\n",
    "        best_params = {k: df_results.loc[best_idx, k] for k in param_names}\n",
    "        print(f\"\\nBest parameters for {method_name}:\")\n",
    "        for k, v in best_params.items():\n",
    "            print(f\"  {k}: {v}\")\n",
    "        print(f\"Target Error: {df_results.loc[best_idx, 'target_error']:.4f}\")\n",
    "        print(f\"Out-of-sample Log Loss: {df_results.loc[best_idx, 'out_sample_logloss']:.4f}\")\n",
    "    \n",
    "    return df_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-18T12:01:34.396784Z",
     "start_time": "2025-03-18T12:01:34.382099Z"
    }
   },
   "id": "b58dd894203316c0",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "434a693888cc67d6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "259ed44e847388b6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1975a4cf7b2ef04f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "22d1d51535d4f145"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c77ef7e9d74e7bb5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5e70761dbc31304c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def cross_validate_hyperparams(df, method, param_grid, method_name, n_folds=5, \n",
    "                             use_sgd=False, use_torch=False, \n",
    "                             n_replications=1, seed=42, verbose=True,\n",
    "                             max_workers=8, true_ate_value=None):\n",
    "    \"\"\"\n",
    "    Perform cross-validation to tune hyperparameters with parallel processing\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: pd.DataFrame\n",
    "        Data frame with columns: X1-X4, A, Y, Y1, Y0 (for binary) or true_dr (for continuous)\n",
    "    method: str\n",
    "        Classification method ('logit', 'boosting', 'neural_net', etc.)\n",
    "    param_grid: dict\n",
    "        Dictionary mapping parameter names to lists of values to try\n",
    "    method_name: str\n",
    "        Name to identify this method in results\n",
    "    n_folds: int\n",
    "        Number of cross-validation folds\n",
    "    use_sgd: bool\n",
    "        Whether to use SGD-based training\n",
    "    use_torch: bool\n",
    "        Whether to use PyTorch-based training\n",
    "    n_replications: int\n",
    "        Number of permutation replications for PW\n",
    "    seed: int\n",
    "        Random seed for reproducibility\n",
    "    verbose: bool\n",
    "        Whether to print progress information\n",
    "    max_workers: int\n",
    "        Maximum number of parallel workers\n",
    "    true_ate_value: float\n",
    "        True ATE value for evaluation (if None, will be calculated from data)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    results: pd.DataFrame\n",
    "        Data frame with results of cross-validation\n",
    "    \"\"\"\n",
    "    import concurrent.futures\n",
    "    \n",
    "    # Extract features and target\n",
    "    feature_cols = [col for col in df.columns if col.startswith('X') and not col.endswith('_mis')]\n",
    "    X = df[feature_cols].values\n",
    "    A = df['A'].values\n",
    "    \n",
    "    # Determine if treatment is continuous\n",
    "    continuous_treatment = 'true_dr' in df.columns\n",
    "    \n",
    "    # Set up cross-validation\n",
    "    from sklearn.model_selection import KFold\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "    cv_splits = list(kf.split(X))\n",
    "    \n",
    "    # Set true target value for binary treatment\n",
    "    if not continuous_treatment:\n",
    "        if true_ate_value is None:\n",
    "            # Calculate from potential outcomes if available\n",
    "            if 'Y1' in df.columns and 'Y0' in df.columns:\n",
    "                true_ate_value = np.mean(df['Y1'] - df['Y0'])\n",
    "            else:\n",
    "                true_ate_value = 1.0  # Default value for Kang-Schafer simulation\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Using True ATE: {true_ate_value:.4f}\")\n",
    "    else:\n",
    "        true_ate_value = None\n",
    "    \n",
    "    # Generate all parameter combinations\n",
    "    param_names = list(param_grid.keys())\n",
    "    param_values = list(itertools.product(*param_grid.values()))\n",
    "    \n",
    "    # Progress tracking\n",
    "    total_combos = len(param_values)\n",
    "    if verbose:\n",
    "        print(f\"Running {total_combos} parameter combinations for {method_name} using up to {max_workers} workers...\")\n",
    "    \n",
    "    # Track time\n",
    "    start_time = time.time()\n",
    "    \n",
    "\n",
    "    \n",
    "    # Run evaluations in parallel\n",
    "    results = []\n",
    "    \n",
    "    # Use ProcessPoolExecutor for better performance with numerical computations\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [executor.submit(evaluate_params, (i, values)) for i, values in enumerate(param_values)]\n",
    "        \n",
    "        # Process results as they complete\n",
    "        for i, future in enumerate(concurrent.futures.as_completed(futures)):\n",
    "            if verbose and i % max(1, total_combos // 10) == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                print(f\"Processed {i+1}/{total_combos} combinations - Elapsed: {elapsed:.1f}s\")\n",
    "            \n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                results.append(result)\n",
    "    \n",
    "    # Create DataFrame from results\n",
    "    df_results = pd.DataFrame([r for r in results if r is not None])\n",
    "    \n",
    "    # Sort by target error\n",
    "    if not df_results.empty:\n",
    "        df_results = df_results.sort_values('target_error')\n",
    "    \n",
    "    # Print best parameters\n",
    "    if verbose and not df_results.empty:\n",
    "        best_idx = df_results['target_error'].idxmin()\n",
    "        best_params = {k: df_results.loc[best_idx, k] for k in param_names}\n",
    "        print(f\"\\nBest parameters for {method_name}:\")\n",
    "        for k, v in best_params.items():\n",
    "            print(f\"  {k}: {v}\")\n",
    "        print(f\"Target Error: {df_results.loc[best_idx, 'target_error']:.4f}\")\n",
    "        print(f\"Out-of-sample Log Loss: {df_results.loc[best_idx, 'out_sample_logloss']:.4f}\")\n",
    "    \n",
    "    return df_results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1fdb2e1fbf52c1f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4fd95e5aa87e7080"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Updated cross_validate_hyperparams function \n",
    "def cross_validate_hyperparams(df, method, param_grid, method_name, n_folds=5, \n",
    "                             use_sgd=False, use_torch=False, \n",
    "                             n_replications=1, seed=42, verbose=True,\n",
    "                             max_workers=8, true_ate_value=None):\n",
    "    \"\"\"\n",
    "    Perform cross-validation to tune hyperparameters with parallel processing\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: pd.DataFrame\n",
    "        Data frame with columns: X1-X4, A, Y, Y1, Y0 (for binary) or true_dr (for continuous)\n",
    "    method: str\n",
    "        Classification method ('logit', 'boosting', 'neural_net', etc.)\n",
    "    param_grid: dict\n",
    "        Dictionary mapping parameter names to lists of values to try\n",
    "    method_name: str\n",
    "        Name to identify this method in results\n",
    "    n_folds: int\n",
    "        Number of cross-validation folds\n",
    "    use_sgd: bool\n",
    "        Whether to use SGD-based training\n",
    "    use_torch: bool\n",
    "        Whether to use PyTorch-based training\n",
    "    n_replications: int\n",
    "        Number of permutation replications for PW\n",
    "    seed: int\n",
    "        Random seed for reproducibility\n",
    "    verbose: bool\n",
    "        Whether to print progress information\n",
    "    max_workers: int\n",
    "        Maximum number of parallel workers\n",
    "    true_ate_value: float\n",
    "        True ATE value for evaluation (if None, will be calculated from data)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    results: pd.DataFrame\n",
    "        Data frame with results of cross-validation\n",
    "    \"\"\"\n",
    "    from data_utils import evaluate_ate_binary, evaluate_dose_response_continuous\n",
    "    \n",
    "    # Extract features and target\n",
    "    feature_cols = [col for col in df.columns if col.startswith('X') and not col.endswith('_mis')]\n",
    "    X = df[feature_cols].values\n",
    "    A = df['A'].values\n",
    "    \n",
    "    # Determine if treatment is continuous\n",
    "    continuous_treatment = 'true_dr' in df.columns\n",
    "    \n",
    "    # Set up cross-validation\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "    cv_splits = list(kf.split(X))\n",
    "    \n",
    "    # Set true target value for binary treatment\n",
    "    if not continuous_treatment:\n",
    "        if true_ate_value is None:\n",
    "            # Calculate from potential outcomes if available\n",
    "            if 'Y1' in df.columns and 'Y0' in df.columns:\n",
    "                true_ate_value = np.mean(df['Y1'] - df['Y0'])\n",
    "            else:\n",
    "                true_ate_value = 1.0  # Default value for Kang-Schafer simulation\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Using True ATE: {true_ate_value:.4f}\")\n",
    "    else:\n",
    "        true_ate_value = None\n",
    "    \n",
    "    # Generate all parameter combinations\n",
    "    param_names = list(param_grid.keys())\n",
    "    param_values = list(itertools.product(*param_grid.values()))\n",
    "    \n",
    "    # Progress tracking\n",
    "    total_combos = len(param_values)\n",
    "    if verbose:\n",
    "        print(f\"Running {total_combos} parameter combinations for {method_name} using up to {max_workers} workers...\")\n",
    "    \n",
    "    # Track time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Run evaluations in parallel\n",
    "    results = []\n",
    "    \n",
    "    # Instead of using ProcessPoolExecutor, use ThreadPoolExecutor for Mac\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = []\n",
    "        \n",
    "        # Submit tasks\n",
    "        for i, values in enumerate(param_values):\n",
    "            # Note we're passing all the needed parameters explicitly\n",
    "            futures.append(executor.submit(\n",
    "                evaluate_params,\n",
    "                (i, values),\n",
    "                X=X,\n",
    "                A=A,\n",
    "                df=df,\n",
    "                cv_splits=cv_splits,\n",
    "                method=method,\n",
    "                n_replications=n_replications,\n",
    "                use_sgd=use_sgd,\n",
    "                use_torch=use_torch,\n",
    "                true_ate_value=true_ate_value,\n",
    "                continuous_treatment=continuous_treatment,\n",
    "                method_name=method_name,\n",
    "                param_names=param_names,\n",
    "                evaluate_ate_binary=evaluate_ate_binary,\n",
    "                evaluate_dose_response_continuous=evaluate_dose_response_continuous\n",
    "            ))\n",
    "        \n",
    "        # Process results as they complete\n",
    "        for i, future in enumerate(concurrent.futures.as_completed(futures)):\n",
    "            if verbose and i % max(1, total_combos // 10) == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                print(f\"Processed {i+1}/{total_combos} combinations - Elapsed: {elapsed:.1f}s\")\n",
    "            \n",
    "            try:\n",
    "                result = future.result()\n",
    "                if result is not None:\n",
    "                    results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing result: {e}\")\n",
    "    \n",
    "    # Create DataFrame from results\n",
    "    df_results = pd.DataFrame([r for r in results if r is not None])\n",
    "    \n",
    "    # Sort by target error\n",
    "    if not df_results.empty:\n",
    "        df_results = df_results.sort_values('target_error')\n",
    "    \n",
    "    # Print best parameters\n",
    "    if verbose and not df_results.empty:\n",
    "        best_idx = df_results['target_error'].idxmin()\n",
    "        best_params = {k: df_results.loc[best_idx, k] for k in param_names}\n",
    "        print(f\"\\nBest parameters for {method_name}:\")\n",
    "        for k, v in best_params.items():\n",
    "            print(f\"  {k}: {v}\")\n",
    "        print(f\"Target Error: {df_results.loc[best_idx, 'target_error']:.4f}\")\n",
    "        print(f\"Out-of-sample Log Loss: {df_results.loc[best_idx, 'out_sample_logloss']:.4f}\")\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "# You can then use this in your main_hyperparameter_tuning function\n",
    "# Just change concurrent.futures.ThreadPoolExecutor with ThreadPoolExecutor"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "335b6051685349f1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
