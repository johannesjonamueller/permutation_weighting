{
    "Standard Logistic": {
        "ate_error": 2.064383828442027,
        "in_sample_logloss": 0.72616133990491,
        "out_sample_logloss": 0.731079632749054,
        "C": 10.0,
        "penalty": "l2",
        "solver": "saga",
        "n_estimators": NaN,
        "learning_rate": NaN,
        "max_depth": NaN,
        "loss": NaN,
        "alpha": NaN,
        "eta0": NaN,
        "hidden_layer_sizes": NaN,
        "activation": NaN,
        "learning_rate_init": NaN,
        "max_iter": NaN,
        "l2_reg": NaN,
        "epochs": NaN,
        "hidden_dims": NaN
    },
    "Gradient Boosting": {
        "ate_error": 4.968290404657244,
        "in_sample_logloss": 0.706171454067772,
        "out_sample_logloss": 0.7396865087870965,
        "C": NaN,
        "penalty": NaN,
        "solver": NaN,
        "n_estimators": 100.0,
        "learning_rate": 0.1,
        "max_depth": 3.0,
        "loss": NaN,
        "alpha": NaN,
        "eta0": NaN,
        "hidden_layer_sizes": NaN,
        "activation": NaN,
        "learning_rate_init": NaN,
        "max_iter": NaN,
        "l2_reg": NaN,
        "epochs": NaN,
        "hidden_dims": NaN
    },
    "SGD Logistic": {
        "ate_error": 15.623520566384036,
        "in_sample_logloss": 0.7078178280480756,
        "out_sample_logloss": 0.6847335927185391,
        "C": NaN,
        "penalty": "l1",
        "solver": NaN,
        "n_estimators": NaN,
        "learning_rate": "optimal",
        "max_depth": NaN,
        "loss": "log_loss",
        "alpha": 0.0001,
        "eta0": 0.01,
        "hidden_layer_sizes": NaN,
        "activation": NaN,
        "learning_rate_init": NaN,
        "max_iter": NaN,
        "l2_reg": NaN,
        "epochs": NaN,
        "hidden_dims": NaN
    },
    "Neural Network": {
        "ate_error": 14.607466561162147,
        "in_sample_logloss": 0.6631362951609298,
        "out_sample_logloss": 0.7077087684696128,
        "C": NaN,
        "penalty": NaN,
        "solver": NaN,
        "n_estimators": NaN,
        "learning_rate": NaN,
        "max_depth": NaN,
        "loss": NaN,
        "alpha": 0.0001,
        "eta0": NaN,
        "hidden_layer_sizes": [
            20
        ],
        "activation": "tanh",
        "learning_rate_init": 0.1,
        "max_iter": 200.0,
        "l2_reg": NaN,
        "epochs": NaN,
        "hidden_dims": NaN
    },
    "PyTorch Logistic": {
        "ate_error": 2.024394344012683,
        "in_sample_logloss": 0.7275314331054688,
        "out_sample_logloss": 0.7246705293655396,
        "C": NaN,
        "penalty": NaN,
        "solver": NaN,
        "n_estimators": NaN,
        "learning_rate": 0.01,
        "max_depth": NaN,
        "loss": NaN,
        "alpha": NaN,
        "eta0": NaN,
        "hidden_layer_sizes": NaN,
        "activation": NaN,
        "learning_rate_init": NaN,
        "max_iter": NaN,
        "l2_reg": 0.0001,
        "epochs": 50.0,
        "hidden_dims": NaN
    },
    "PyTorch MLP": {
        "ate_error": 0.5167532959372806,
        "in_sample_logloss": 0.7243267893791199,
        "out_sample_logloss": 0.7317174077033997,
        "C": NaN,
        "penalty": NaN,
        "solver": NaN,
        "n_estimators": NaN,
        "learning_rate": 0.001,
        "max_depth": NaN,
        "loss": NaN,
        "alpha": NaN,
        "eta0": NaN,
        "hidden_layer_sizes": NaN,
        "activation": NaN,
        "learning_rate_init": NaN,
        "max_iter": NaN,
        "l2_reg": 0.0001,
        "epochs": 50.0,
        "hidden_dims": "[16, 8]"
    }
}