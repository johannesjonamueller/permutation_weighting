{
    "Standard Logistic": {
        "ate_error": 2.064383828442027,
        "in_sample_logloss": 0.72616133990491,
        "out_sample_logloss": 0.731079632749054,
        "C": 10.0,
        "penalty": "l2",
        "solver": "saga",
        "n_estimators": NaN,
        "learning_rate": NaN,
        "max_depth": NaN,
        "loss": NaN,
        "alpha": NaN,
        "eta0": NaN,
        "hidden_layer_sizes": NaN,
        "activation": NaN,
        "learning_rate_init": NaN,
        "max_iter": NaN,
        "l2_reg": NaN,
        "epochs": NaN,
        "hidden_dims": NaN
    },
    "Gradient Boosting": {
        "ate_error": 4.968290404657244,
        "in_sample_logloss": 0.706171454067772,
        "out_sample_logloss": 0.7396865087870965,
        "C": NaN,
        "penalty": NaN,
        "solver": NaN,
        "n_estimators": 100.0,
        "learning_rate": 0.1,
        "max_depth": 3.0,
        "loss": NaN,
        "alpha": NaN,
        "eta0": NaN,
        "hidden_layer_sizes": NaN,
        "activation": NaN,
        "learning_rate_init": NaN,
        "max_iter": NaN,
        "l2_reg": NaN,
        "epochs": NaN,
        "hidden_dims": NaN
    },
    "SGD Logistic": {
        "ate_error": 15.623520566384036,
        "in_sample_logloss": 0.7078178280480756,
        "out_sample_logloss": 0.6847335927185391,
        "C": NaN,
        "penalty": "l1",
        "solver": NaN,
        "n_estimators": NaN,
        "learning_rate": "optimal",
        "max_depth": NaN,
        "loss": "log_loss",
        "alpha": 0.0001,
        "eta0": 0.01,
        "hidden_layer_sizes": NaN,
        "activation": NaN,
        "learning_rate_init": NaN,
        "max_iter": NaN,
        "l2_reg": NaN,
        "epochs": NaN,
        "hidden_dims": NaN
    },
    "Neural Network": {
        "ate_error": 15.569733554906918,
        "in_sample_logloss": 0.6685765256521253,
        "out_sample_logloss": 0.6754397839730067,
        "C": NaN,
        "penalty": NaN,
        "solver": NaN,
        "n_estimators": NaN,
        "learning_rate": NaN,
        "max_depth": NaN,
        "loss": NaN,
        "alpha": 0.0001,
        "eta0": NaN,
        "hidden_layer_sizes": [
            20
        ],
        "activation": "tanh",
        "learning_rate_init": 0.1,
        "max_iter": 200.0,
        "l2_reg": NaN,
        "epochs": NaN,
        "hidden_dims": NaN
    },
    "PyTorch Logistic": {
        "ate_error": 1.8086343067047779,
        "in_sample_logloss": 0.7269757986068726,
        "out_sample_logloss": 0.725247323513031,
        "C": NaN,
        "penalty": NaN,
        "solver": NaN,
        "n_estimators": NaN,
        "learning_rate": 0.01,
        "max_depth": NaN,
        "loss": NaN,
        "alpha": NaN,
        "eta0": NaN,
        "hidden_layer_sizes": NaN,
        "activation": NaN,
        "learning_rate_init": NaN,
        "max_iter": NaN,
        "l2_reg": 0.0001,
        "epochs": 50.0,
        "hidden_dims": NaN
    },
    "PyTorch MLP": {
        "ate_error": 0.3621607409174941,
        "in_sample_logloss": 0.7227330207824707,
        "out_sample_logloss": 0.7335850596427917,
        "C": NaN,
        "penalty": NaN,
        "solver": NaN,
        "n_estimators": NaN,
        "learning_rate": 0.01,
        "max_depth": NaN,
        "loss": NaN,
        "alpha": NaN,
        "eta0": NaN,
        "hidden_layer_sizes": NaN,
        "activation": NaN,
        "learning_rate_init": NaN,
        "max_iter": NaN,
        "l2_reg": 0.0001,
        "epochs": 50.0,
        "hidden_dims": "[16]"
    }
}